{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA73kHLLdKHT"
      },
      "source": [
        "Final model: the one used to predict instances outside the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDvUgsfjdvmO"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "575CB7jEdSr0"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix, accuracy_score\n",
        "from sklearn import svm, tree\n",
        "from sklearn.model_selection import KFold,cross_val_score\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix, hstack"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggUAiYJZdzPq"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkEPHiZLd03s",
        "outputId": "f0d4659e-5d20-4056-9382-22565dd2c564",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = pd.read_json(\"drive/My Drive/ML/HW1/processed_dataset.json\",lines=True)\n",
        "\n",
        "vectorizer = CountVectorizer(min_df=0.005)\n",
        "y_all = dataset['semantic']\n",
        "X1 = vectorizer.fit_transform(dataset['instructions'])\n",
        "\n",
        "columns=vectorizer.get_feature_names()\n",
        "\n",
        "#adding number of edges\n",
        "edges=dataset['edges']\n",
        "l=len(edges)\n",
        "rows=np.arange(0,l)\n",
        "cols=np.full((l), 0, dtype=int)\n",
        "X2=csr_matrix((edges, (rows, cols)),shape=(l, 1)).toarray()\n",
        "X_tmp2=hstack((X1,X2))\n",
        "columns.append('edges')\n",
        "\n",
        "#adding cycles(true/false)\n",
        "cycles=dataset['cycles']\n",
        "X3=csr_matrix((cycles, (rows, cols)),shape=(l, 1)).toarray()\n",
        "X_tmp=hstack((X_tmp2,X3))\n",
        "columns.append('has_cycles')\n",
        "\n",
        "\n",
        "#adding cyclomatic complexity\n",
        "cyclo=dataset['cyclomatic']\n",
        "X4=csr_matrix((cyclo, (rows, cols)),shape=(l, 1)).toarray()\n",
        "X_all=hstack((X_tmp,X4))\n",
        "columns.append('cyclomatic_c')\n",
        "\n",
        "#Splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
        "          test_size=0.2, random_state=15)\n",
        "id = random.randrange(0,X_train.shape[0])\n",
        "\n",
        "start=time.time()\n",
        "#model = MultinomialNB().fit(X_train, y_train)\n",
        "model = svm.SVC(kernel = 'linear', C=1).fit(X_train, y_train)\n",
        "t=time.time()-start\n",
        "print(\"training running time: \"+str(t)+\" sec\")\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training running time: 42.093008279800415 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVqT_kDGecdx"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD8LUnP0edhf",
        "outputId": "ce3e9a8c-184d-4b3d-8675-4397b310fc2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "cm=confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"accuracy_score: \"+str(accuracy_score(y_test,y_pred, normalize=True)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[557   0   1   0]\n",
            " [  0 922   5   0]\n",
            " [  0   2 785   9]\n",
            " [  0   1  34 564]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  encryption       1.00      1.00      1.00       558\n",
            "        math       1.00      0.99      1.00       927\n",
            "        sort       0.95      0.99      0.97       796\n",
            "      string       0.98      0.94      0.96       599\n",
            "\n",
            "    accuracy                           0.98      2880\n",
            "   macro avg       0.98      0.98      0.98      2880\n",
            "weighted avg       0.98      0.98      0.98      2880\n",
            "\n",
            "accuracy_score: 0.9819444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1jw4rEyefWI"
      },
      "source": [
        "Prediction on the blind test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJyMvNkeeh5v",
        "outputId": "815220eb-5b69-49fe-e49f-bbd1344d03f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "newfile=open(\"drive/My Drive/ML/HW1/1796480.txt\",\"w\")\n",
        "blindtest = pd.read_json(\"drive/My Drive/ML/HW1/processed_blindtest.json\",lines=True)\n",
        "\n",
        "X1=vectorizer.transform(blindtest['instructions'])\n",
        "\n",
        "#adding number of edges\n",
        "edges=blindtest['edges']\n",
        "l=len(edges)\n",
        "rows=np.arange(0,l)\n",
        "cols=np.full((l), 0, dtype=int)\n",
        "X2=csr_matrix((edges, (rows, cols)),shape=(l, 1)).toarray()\n",
        "X_tmp2=hstack((X1,X2))\n",
        "\n",
        "#adding cycles(true/false)\n",
        "cycles=blindtest['cycles']\n",
        "X3=csr_matrix((cycles, (rows, cols)),shape=(l, 1)).toarray()\n",
        "X_tmp=hstack((X_tmp2,X3))\n",
        "\n",
        "\n",
        "#adding cyclomatic complexity\n",
        "cyclo=blindtest['cyclomatic']\n",
        "X4=csr_matrix((cyclo, (rows, cols)),shape=(l, 1)).toarray()\n",
        "X_all=hstack((X_tmp,X4))\n",
        "\n",
        "\n",
        "predictions=model.predict(X_all)\n",
        "for pred in predictions:\n",
        "  newfile.write(pred+'\\n')\n",
        "newfile.close()\n",
        "print(\"Results in 1796480.txt!\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results in 1796480.txt!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}